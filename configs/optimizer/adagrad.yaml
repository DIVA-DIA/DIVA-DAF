# explanation of the different parameters: https://pytorch.org/docs/stable/generated/torch.optim.Adagrad.html#torch.optim.Adagrad

_target_: torch.optim.Adagrad

lr: 1e-3
lr_decay: 0
weight_decay: 0
initial_accumulator_value: 0
eps: 1e-10