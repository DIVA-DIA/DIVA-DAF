_target_: src.models.backbones.mlp.MLP

#path_to_weights: 'path/to/checkpoint' # path to the checkpoint(.pth) with surrounded with ''
#strict: False  # if you want to load the weights in a non-strict manner (https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict) (load_state_dict())

in_channels: ${datamodule:embedding_size}
hidden_channels:
  - 512
  - 16
